# Username and Passwords
gLoginUsername=vijayabh
gPassword=XXXXXXXXXX
googleLoginUsername=vijayabh@google.com
# Selenium browser window size
windowSize=1920x1080
#1920x1040
dataplexurl=https://pantheon.corp.google.com/dataplex/lakes?project=dataplex-cdf&pli=1
#dataplexurl=https://pantheon-hourly-sso.corp.google.com/dataplex/lakes?project=dataplex-cdf&pli=1
googlesignin=https://accounts.google.com/signin/v2/identifier?flowName=GlifWebSignIn&flowEntry=ServiceLogin
gcsnotebookurl=https://7e0438d3-39a8-4ff5-a88f-563c0ddc09fe-dot-usc1.dataplex.googleusercontent.com/environment/default-six/notebooks/test-gcs-notebook.ipynb
bqnotebookurl=https://7e0438d3-39a8-4ff5-a88f-563c0ddc09fe-dot-usc1.dataplex.googleusercontent.com/environment/default-six/notebooks/test-bq-notebook.ipynb
BigQuery=https://pantheon.corp.google.com/bigquery?project=cdf-athena
# Service Account
ServiceAccount=651750992634-compute@developer.gserviceaccount.com
# Queries for SQL WorkBench
Query1=select * from merazone.5k_data limit 10;
Query2=show databases;
# GCS Commands for Jupyter NoteBook
Command1=import time\nBUCKET_NAME='analyze-test-' + str(time.time_ns())\nprint('Bucket: ' + BUCKET_NAME)
Command1Result=Bucket: analyze-test-
Command2=!gsutil mb gs://$BUCKET_NAME
Command2Result=Creating gs://analyze-test-
#GCS Path for Spark & PySpark Tasks
ClassName1=com.test.TestSpark
Spark1GCSPath=gs://e2e-automation-testdata-bucket/task/spark-jar/helloworld-spark.jar
Spark2GCSPath=gs://e2e-automation-testdata-bucket/task/spark-jar/sparkjar-with-mainclass.jar
PySpark1GCSPath=gs://e2e-automation-testdata-bucket/task/pyspark/HelloWorld.py
